# src/model_train.py

import pandas as pd
import numpy as np
from sqlalchemy import create_engine
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score
import joblib
import logging
import os

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class SalaryPredictor:
    """
    è–ªèµ„é¢„æµ‹æ¨¡å‹ç±» (Proç‰ˆ)
    è´Ÿè´£ï¼šè‡ªåŠ¨åŠ è½½æ¸…æ´—åçš„æ•°æ® -> ç‰¹å¾å·¥ç¨‹é€‚é… -> éšæœºæ£®æ—å»ºæ¨¡ -> è¯„ä¼°ä¸æŒä¹…åŒ–
    """
    def __init__(self):
        # --- 1. æ™ºèƒ½è·¯å¾„è¯†åˆ« (ä¸ ETL ä¿æŒä¸€è‡´) ---
        base_dir = os.getcwd()
        if 'src' in base_dir: 
            base_dir = os.path.dirname(base_dir)
            
        # æ•°æ®åº“è·¯å¾„
        abs_db_path = os.path.join(base_dir, 'data', 'job_data.db')
        self.db_url = f'sqlite:///{abs_db_path}'
        
        # æ¨¡å‹ä¿å­˜è·¯å¾„
        self.model_path = os.path.join(base_dir, 'data', 'salary_model.pkl')
        
        self.engine = create_engine(self.db_url)
        self.table_name = 'cleaned_jobs_with_features'
        self.model = None
        self.feature_names = None 
        
        logging.info(f"ğŸ¤– æ¨¡å‹ç³»ç»Ÿåˆå§‹åŒ– | DB: {self.db_url}")

    def load_and_preprocess(self):
        """
        åŠ è½½æ•°æ®å¹¶è¿›è¡Œç‰¹å¾é¢„å¤„ç† (é€‚é…æ–°çš„ ETL ç»“æ„)
        """
        logging.info("ğŸ“¥ æ­£åœ¨ä»æ•°æ®åº“åŠ è½½è®­ç»ƒæ•°æ®...")
        
        try:
            df = pd.read_sql(f"SELECT * FROM {self.table_name}", self.engine)
        except Exception as e:
            raise ValueError(f"æ— æ³•è¯»å–æ•°æ®åº“è¡¨ '{self.table_name}'ï¼Œè¯·å…ˆè¿è¡Œ etl_pipeline.pyï¼é”™è¯¯: {e}")

        if len(df) < 10:
            raise ValueError("æ•°æ®é‡å¤ªå°‘ (<10æ¡)ï¼Œæ— æ³•è¿›è¡Œæœ‰æ•ˆè®­ç»ƒã€‚è¯·å…ˆè¿è¡Œçˆ¬è™«æŠ“å–æ›´å¤šæ•°æ®ï¼")

        # --- 1.5. å…³é”®ä¿®å¤ï¼šè¿‡æ»¤æ‰å­¦å†ä¸é™(degree_value=0)çš„æ ·æœ¬ ---
        # å­¦å†ä¸é™çš„å²—ä½ä¸åº”è¯¥å‚ä¸å­¦å†ç›¸å…³çš„è–ªèµ„é¢„æµ‹ï¼Œå› ä¸ºå®ƒä»¬æ²¡æœ‰æ˜ç¡®çš„å­¦å†è¦æ±‚
        original_count = len(df)
        df = df[df['degree_value'] > 0].copy()  # åªä¿ç•™æ˜ç¡®çš„å­¦å†è¦æ±‚ï¼ˆ1=å¤§ä¸“, 2=æœ¬ç§‘, 3=ç¡•å£«, 4=åšå£«ï¼‰
        filtered_count = original_count - len(df)
        if filtered_count > 0:
            logging.info(f"   âš ï¸ å·²è¿‡æ»¤ {filtered_count} ä¸ª'å­¦å†ä¸é™'æ ·æœ¬ï¼ˆä¸å‚ä¸å­¦å†ç›¸å…³é¢„æµ‹ï¼‰")
        
        # --- 1.6. é¢å¤–ä¿®å¤ï¼šè¿‡æ»¤å¼‚å¸¸é«˜è–ªæ ·æœ¬ï¼ˆå¯èƒ½æ˜¯æ•°æ®è§£æé”™è¯¯ï¼‰---
        # å¯¹äºæ•°æ®åˆ†æå¸ˆå²—ä½ï¼Œæœˆè–ªè¶…è¿‡5ä¸‡é€šå¸¸å¼‚å¸¸ï¼ˆå¯èƒ½æ˜¯OCRé”™è¯¯æˆ–å•ä½é”™è¯¯ï¼‰
        original_count2 = len(df)
        df = df[df['avg_salary'] < 50000].copy()
        filtered_count2 = original_count2 - len(df)
        if filtered_count2 > 0:
            logging.info(f"   âš ï¸ å·²è¿‡æ»¤ {filtered_count2} ä¸ªå¼‚å¸¸é«˜è–ªæ ·æœ¬ï¼ˆ>5ä¸‡/æœˆï¼Œå¯èƒ½æ˜¯æ•°æ®é”™è¯¯ï¼‰")
        
        if len(df) < 10:
            raise ValueError(f"è¿‡æ»¤åæ•°æ®é‡å¤ªå°‘ (<10æ¡)ï¼Œæ— æ³•è¿›è¡Œæœ‰æ•ˆè®­ç»ƒã€‚")

        # --- 2. é€‰å®šç‰¹å¾åˆ— (Feature Selection) ---
        # æ•°å€¼å‹ç‰¹å¾ (ç›´æ¥ä½¿ç”¨)
        numeric_features = ['exp_years']  # ä¿®å¤ï¼šå°†degree_valueä»æ•°å€¼ç‰¹å¾ä¸­ç§»é™¤
        
        # ç±»åˆ«å‹ç‰¹å¾ (éœ€è¦ One-Hot ç¼–ç )
        # ä¿®å¤ï¼šå°†å­¦å†ä¹Ÿä½œä¸ºç±»åˆ«ç‰¹å¾ï¼Œé¿å…æ¨¡å‹å­¦ä¹ é”™è¯¯çš„æ•°å€¼å…³ç³»
        categorical_features = ['city_clean', 'degree_value']
        
        # æŠ€èƒ½ç‰¹å¾ (äºŒè¿›åˆ¶ 0/1, ç›´æ¥ä½¿ç”¨)
        skill_features = [col for col in df.columns if col.startswith('has_')]
        
        # ç›®æ ‡å˜é‡
        target_col = 'avg_salary'
        
        logging.info(f"   ä½¿ç”¨çš„æŠ€èƒ½ç‰¹å¾: {skill_features}")
        logging.info(f"   âš ï¸ é‡è¦ä¿®å¤ï¼šå­¦å†(degree_value)å·²æ”¹ä¸ºç±»åˆ«ç‰¹å¾ï¼Œé¿å…æ•°å€¼å…³ç³»é”™è¯¯")
        
        # å‡†å¤‡ X å’Œ y
        # ç»„åˆæ‰€æœ‰éœ€è¦çš„åˆ—
        needed_cols = numeric_features + categorical_features + skill_features
        X = df[needed_cols].copy()
        y = df[target_col]
        
        # --- 3. ç‰¹å¾ç¼–ç  (Encoding) ---
        # å¯¹åŸå¸‚å’Œå­¦å†è¿›è¡Œ One-Hot ç¼–ç 
        # ä¾‹å¦‚: city_clean_å—äº¬ = 1, degree_value_2 = 1 (è¡¨ç¤ºæœ¬ç§‘)
        # æ³¨æ„ï¼šç”±äºå·²ç»è¿‡æ»¤äº†degree_value=0ï¼Œæ‰€ä»¥ä¸ä¼šç”Ÿæˆdegree_value_0ç‰¹å¾
        X = pd.get_dummies(X, columns=categorical_features, drop_first=False)
        
        # éªŒè¯ï¼šç¡®ä¿æ²¡æœ‰degree_value_0ç‰¹å¾ï¼ˆå¦‚æœå­˜åœ¨è¯´æ˜è¿‡æ»¤å¤±è´¥ï¼‰
        degree_0_cols = [col for col in X.columns if 'degree_value_0' in col]
        if degree_0_cols:
            logging.warning(f"   âš ï¸ è­¦å‘Šï¼šå‘ç°degree_value_0ç‰¹å¾åˆ— {degree_0_cols}ï¼Œè¿™ä¸åº”è¯¥å­˜åœ¨ï¼")
        
        # è®°å½•æœ€ç»ˆçš„ç‰¹å¾åç§°åˆ—è¡¨ (é¢„æµ‹æ—¶å¿…é¡»ä¿æŒä¸€è‡´)
        self.feature_names = X.columns.tolist()
        
        logging.info(f"âœ¨ ç‰¹å¾å·¥ç¨‹å®Œæˆ: æ ·æœ¬æ•°={len(X)}, ç‰¹å¾ç»´åº¦={len(self.feature_names)}")
        return X, y

    def train(self):
        """æ‰§è¡Œè®­ç»ƒæµç¨‹"""
        try:
            X, y = self.load_and_preprocess()
            
            # åˆ’åˆ†æ•°æ®é›† (80% è®­ç»ƒ, 20% éªŒè¯)
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            
            logging.info("ğŸ”¥ å¼€å§‹è®­ç»ƒéšæœºæ£®æ—å›å½’æ¨¡å‹ (RandomForestRegressor)...")
            
            # åˆå§‹åŒ–æ¨¡å‹
            # n_estimators=200: æ ‘è¶Šå¤šè¶Šç¨³å®š
            # max_depth=None: è®©æ ‘è‡ªç„¶ç”Ÿé•¿ï¼Œæ•æ‰å¤æ‚å…³ç³»
            # n_jobs=-1:ä»¥æ­¤ç”µè„‘æœ€å¤§æ ¸å¿ƒæ•°å¹¶è¡Œè®­ç»ƒ
            self.model = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)
            self.model.fit(X_train, y_train)
            
            # è¯„ä¼°
            score_train = self.model.score(X_train, y_train)
            score_test = self.model.score(X_test, y_test)
            y_pred = self.model.predict(X_test)
            mae = mean_absolute_error(y_test, y_pred)
            
            print("\n" + "="*40)
            print("ğŸ“Š æ¨¡å‹è¯„ä¼°æŠ¥å‘Š (Model Evaluation)")
            print("="*40)
            print(f"è®­ç»ƒé›† RÂ² å¾—åˆ†: {score_train:.4f}")
            print(f"æµ‹è¯•é›† RÂ² å¾—åˆ†: {score_test:.4f} (æ ¸å¿ƒæŒ‡æ ‡)")
            print(f"å¹³å‡ç»å¯¹è¯¯å·® (MAE): {mae:.2f} å…ƒ")
            print("-" * 40)
            print(f"è§£è¯»: æ¨¡å‹é¢„æµ‹è–ªèµ„çš„å¹³å‡è¯¯å·®çº¦ä¸º {int(mae)} å…ƒã€‚")
            print("="*40 + "\n")
            
            self.analyze_feature_importance()
            self.save_model()
            
        except Exception as e:
            logging.error(f"âŒ è®­ç»ƒå¤±è´¥: {e}")

    def analyze_feature_importance(self):
        """è¾“å‡ºç‰¹å¾é‡è¦æ€§æ’è¡Œæ¦œ"""
        if self.model is None: return
        
        importances = self.model.feature_importances_
        # å°†ç‰¹å¾åå’Œé‡è¦æ€§ç»„åˆ
        feature_imp = pd.DataFrame({
            'Feature': self.feature_names,
            'Importance': importances
        }).sort_values(by='Importance', ascending=False)
        
        print("ğŸ† è–ªèµ„å½±å“å› å­æ’è¡Œæ¦œ (Top 10):")
        print(feature_imp.head(10).to_string(index=False))
        print("\n")

    def save_model(self):
        """ä¿å­˜æ¨¡å‹ä¸ç‰¹å¾å…ƒæ•°æ®"""
        if self.model is None: return
        
        payload = {
            'model': self.model,
            'feature_names': self.feature_names # éå¸¸é‡è¦ï¼šé¢„æµ‹æ—¶éœ€è¦å¯¹ç…§è¿™ä¸ªé¡ºåº
        }
        
        try:
            joblib.dump(payload, self.model_path)
            logging.info(f"ğŸ’¾ æ¨¡å‹å·²æˆåŠŸä¿å­˜è‡³: {self.model_path}")
            logging.info("âœ… ä½ ç°åœ¨å¯ä»¥è¿è¡Œ visual_app.py å¯åŠ¨å¯è§†åŒ–å¤§å±äº†ï¼")
        except Exception as e:
            logging.error(f"ä¿å­˜æ¨¡å‹å¤±è´¥: {e}")

if __name__ == "__main__":
    predictor = SalaryPredictor()
    predictor.train()