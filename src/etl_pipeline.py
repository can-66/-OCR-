# src/etl_pipeline.py

import pandas as pd
import numpy as np
import re
import jieba
from sqlalchemy import create_engine
import logging
import os

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class DataPipeline:
    def __init__(self, csv_path='data/real_job_data.csv', db_path='sqlite:///data/job_data.db'):
        self.csv_path = csv_path
        
        # --- è·¯å¾„è‡ªåŠ¨ä¿®å¤é€»è¾‘ ---
        base_dir = os.getcwd()
        if 'src' in base_dir: 
            base_dir = os.path.dirname(base_dir)
        
        abs_db_path = os.path.join(base_dir, 'data', 'job_data.db')
        self.db_engine_url = f'sqlite:///{abs_db_path}'
        self.engine = create_engine(self.db_engine_url)
        self.clean_table = 'cleaned_jobs_with_features'
        
        logging.info(f"ğŸ”§ ETL åˆå§‹åŒ– | ç›®æ ‡æ•°æ®åº“: {self.db_engine_url}")

    def load_data(self):
        """åŠ è½½æ•°æ®ï¼Œå…¼å®¹å¤šç§ç¼–ç """
        # è‡ªåŠ¨å¯»æ‰¾ CSV æ–‡ä»¶
        if not os.path.exists(self.csv_path):
            alt_path = os.path.join('data', 'real_job_data.csv')
            if os.path.exists(alt_path):
                self.csv_path = alt_path
            else:
                raise FileNotFoundError(f"æ‰¾ä¸åˆ° CSV æ–‡ä»¶: {self.csv_path}")

        try:
            df = pd.read_csv(self.csv_path, encoding='utf-8-sig')
        except:
            df = pd.read_csv(self.csv_path, encoding='gbk')
        
        logging.info(f"ğŸ“¥ åŸå§‹æ•°æ®åŠ è½½æˆåŠŸ: {len(df)} è¡Œ")
        return df

    def _extract_city_smart(self, raw_text):
        """
        ğŸ”¥ æ ¸å¿ƒä¿®å¤ï¼šä»åŸå§‹æ–‡æœ¬ä¸­æå–çœŸå®åŸå¸‚
        ç­–ç•¥ï¼šå€’åºæ‰«æ (Bottom-Up)ï¼Œé¿å¼€å…¬å¸åå¹²æ‰°
        """
        if not isinstance(raw_text, str):
            return "æœªçŸ¥"
            
        lines = raw_text.split('\n')
        target_cities = ['å—äº¬', 'åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³', 'æ­å·', 'æˆéƒ½', 'æ­¦æ±‰', 'è¥¿å®‰', 'è‹å·', 'é•¿æ²™', 'é‡åº†', 'åˆè‚¥']
        company_keywords = ['å…¬å¸', 'ç§‘æŠ€', 'é›†å›¢', 'é“¶è¡Œ', 'è½¯ä»¶', 'æœåŠ¡', 'ä¸­å¿ƒ', 'å¤§å­¦', 'å‚', 'å±€']

        # ã€å…³é”®æ­¥éª¤ã€‘ä»æœ€åä¸€è¡Œå¾€ä¸Šçœ‹ï¼å› ä¸ºåœ°ç‚¹é€šå¸¸åœ¨å¡ç‰‡åº•éƒ¨
        for line in reversed(lines):
            line = line.strip()
            if not line: continue
            
            # 1. ä¼˜å…ˆåŒ¹é…å¸¦â€œÂ·â€çš„æ ¼å¼ (å¦‚ "å—äº¬Â·æ±Ÿå®åŒº")ï¼Œè¿™æ˜¯æœ€å‡†ç¡®çš„åœ°ç‚¹ç‰¹å¾
            if 'Â·' in line:
                # æ£€æŸ¥ç‚¹å·å‰é¢æ˜¯ä¸æ˜¯åŸå¸‚
                part1 = line.split('Â·')[0]
                if any(city in part1 for city in target_cities):
                    return part1 # æ‰¾åˆ°çœŸå®åŸå¸‚ï¼Œç›´æ¥è¿”å›ï¼

            # 2. å¦‚æœæ²¡æœ‰ç‚¹å·ï¼Œæ£€æŸ¥æ˜¯å¦åŒ…å«åŸå¸‚åï¼Œä¸”ä¸æ˜¯å…¬å¸å
            matched_city = None
            for city in target_cities:
                if city in line:
                    matched_city = city
                    break
            
            if matched_city:
                # å¿…é¡»è¿›è¡ŒäºŒæ¬¡æ ¡éªŒï¼šè¿™è¡Œæ˜¯ä¸æ˜¯å…¬å¸åï¼Ÿ
                is_company = False
                for kw in company_keywords:
                    if kw in line:
                        is_company = True
                        break
                
                # ç‰¹ä¾‹ï¼šå¦‚æœè¿™è¡Œå­—æ•°å¾ˆå°‘ï¼Œä¸”å°±æ˜¯åŸå¸‚å (å¦‚ "å—äº¬")ï¼Œé‚£å®ƒè‚¯å®šä¸æ˜¯å…¬å¸
                if len(line) <= 3 and matched_city == line:
                    return matched_city
                
                # å¦‚æœåŒ…å«åŸå¸‚ä½†æ²¡æœ‰å…¬å¸å…³é”®è¯ï¼Œé‡‡çº³
                if not is_company:
                    return matched_city
                    
        return "æœªçŸ¥"

    def _parse_salary(self, salary_str):
        """
        ğŸ”¥ å¼ºåŠ›ä¿®å¤ç‰ˆè–ªèµ„è§£æ
        """
        if pd.isna(salary_str): return np.nan, np.nan, np.nan
        s = str(salary_str).upper().strip()
        
        # === ä¼˜å…ˆå¤„ç†æ ‡å‡†æ ¼å¼ "15-25K" æˆ– "15-25" ===
        # ä¿®å¤ï¼šä¼˜å…ˆåŒ¹é…å¸¦æ¨ªçº¿çš„æ ¼å¼ï¼Œé¿å…"5-6K"è¢«è¯¯è§£æ
        if '-' in s:
            match = re.search(r'(\d+)\s*-\s*(\d+)', s)
            if match:
                low = int(match.group(1))
                high = int(match.group(2))
                # éªŒè¯åˆç†æ€§ï¼šå¦‚æœä¸¤ä¸ªæ•°å­—éƒ½å¾ˆå°ï¼ˆ<50ï¼‰ï¼Œå¾ˆå¯èƒ½æ˜¯Kå•ä½
                # å¦‚æœæ•°å­—è¾ƒå¤§ï¼ˆ>50ï¼‰ï¼Œå¯èƒ½æ˜¯å…ƒå•ä½ï¼Œéœ€è¦é™¤ä»¥1000
                if low > 50 or high > 50:
                    # å¯èƒ½æ˜¯å…ƒå•ä½ï¼Œè½¬æ¢ä¸ºK
                    if low > 1000:
                        low = low / 1000
                        high = high / 1000
                    else:
                        # å¯èƒ½æ˜¯10K-20Kæ ¼å¼ï¼Œå·²ç»æ˜¯Kå•ä½
                        pass
                # å®‰å…¨æ£€æŸ¥
                if low > 200 or high > 200:
                    return np.nan, np.nan, np.nan
                if low > high:
                    low, high = high, low
                # è½¬ä¸ºå®é™…æ•°å€¼ (å•ä½ï¼šå…ƒ)
                return low * 1000, high * 1000, (low + high) * 500
        
        # === å¤„ç†ç²˜è¿æ•°å­—ï¼ˆå¦‚"2140K"ï¼‰===
        nums = re.findall(r'\d+', s)
        if not nums: return np.nan, np.nan, np.nan
        
        raw_val = int(nums[0])
        
        # æƒ…å†µA: å¦‚æœæ•°å­—å·¨å¤§ (æ¯”å¦‚ > 200)ï¼Œä¸”çœ‹èµ·æ¥åƒç²˜è¿æ•°å­—
        if raw_val > 200: 
            s_val = str(raw_val)
            if len(s_val) == 4: # 2140 -> 21, 40
                low = int(s_val[:2])
                high = int(s_val[2:])
            elif len(s_val) == 3: # 812 -> 8, 12
                low = int(s_val[:1])
                high = int(s_val[1:])
            else:
                return np.nan, np.nan, np.nan
        else:
            # æƒ…å†µB: å•ä¸ªæ•°å­— "15K"
            low = raw_val
            high = raw_val

        # === å®‰å…¨å«å£« (Safety Guard) ===
        if low > 200 or high > 200:
            return np.nan, np.nan, np.nan
            
        # é€»è¾‘é”™è¯¯æ£€æŸ¥ (ä½ > é«˜)
        if low > high:
            low, high = high, low
            
        # è½¬ä¸ºå®é™…æ•°å€¼ (å•ä½ï¼šå…ƒ)
        return low * 1000, high * 1000, (low + high) * 500

    def _parse_exp_degree(self, text):
        """åŒæ—¶æå–ç»éªŒå’Œå­¦å†"""
        exp, deg = 0, 0  # ä¿®æ”¹ï¼šé»˜è®¤å­¦å†ä¸º0ï¼ˆæœªçŸ¥ï¼‰ï¼Œè€Œä¸æ˜¯1ï¼ˆå¤§ä¸“ï¼‰
        if not isinstance(text, str): return exp, deg
        
        # ç»éªŒ
        if re.search(r'(\d+)-(\d+)å¹´', text):
            m = re.search(r'(\d+)-(\d+)å¹´', text)
            exp = (float(m.group(1)) + float(m.group(2))) / 2
        elif "åº”å±Š" in text or "åœ¨æ ¡" in text:
            exp = 0.5
        elif re.search(r'(\d+)å¹´', text):
            exp = float(re.search(r'(\d+)å¹´', text).group(1))
            
        # å­¦å† - ä¿®å¤ï¼šä¼˜å…ˆæ£€æŸ¥"å­¦å†ä¸é™"ï¼Œé¿å…è¢«é”™è¯¯æ ‡è®°
        if "å­¦å†ä¸é™" in text or "å­¦å†è¦æ±‚" in text and "ä¸é™" in text:
            deg = 0  # å­¦å†ä¸é™æ ‡è®°ä¸º0
        elif "åšå£«" in text: 
            deg = 4
        elif "ç¡•å£«" in text: 
            deg = 3
        elif "æœ¬ç§‘" in text: 
            deg = 2
        elif "å¤§ä¸“" in text: 
            deg = 1
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•å­¦å†ä¿¡æ¯ï¼Œä¿æŒdeg=0ï¼ˆæœªçŸ¥ï¼‰
        
        return exp, deg

    def clean_data(self, df):
        logging.info("ğŸ§¹ å¼€å§‹æ¸…æ´—...")
        
        # --- 1. ä¿®å¤åŸå¸‚é”™è¯¯ (City Fix) ---
        # ä¸å†ä¿¡ä»»çˆ¬è™«åŸæœ¬çš„ city åˆ—ï¼Œé‡æ–°ä» raw_text æå–
        df['real_city'] = df['raw_text'].apply(self._extract_city_smart)
        # è¦†ç›–åŸåˆ—
        df['city'] = df['real_city']
        df['city_clean'] = df['real_city'] # ç”¨äºåç»­åˆ†æçš„å¹²å‡€åˆ—
        
        # --- 2. è–ªèµ„è§£æ ---
        salary_feats = df['salary'].apply(lambda x: self._parse_salary(x))
        df['min_salary'], df['max_salary'], df['avg_salary'] = zip(*salary_feats)
        df = df.dropna(subset=['avg_salary']) # å‰”é™¤æ— æ•ˆè–ªèµ„
        
        # --- 2.5. å¼‚å¸¸å€¼è¿‡æ»¤ï¼ˆåœ¨ETLé˜¶æ®µå°±è¿‡æ»¤ï¼Œç¡®ä¿æ•°æ®è´¨é‡ï¼‰---
        original_count = len(df)
        # è¿‡æ»¤å¼‚å¸¸é«˜è–ªï¼ˆ>5ä¸‡/æœˆï¼Œå¯¹äºæ•°æ®åˆ†æå¸ˆå²—ä½é€šå¸¸å¼‚å¸¸ï¼‰
        # è¿‡æ»¤å¼‚å¸¸ä½è–ªï¼ˆ<2000/æœˆï¼Œå¯èƒ½æ˜¯æ—¥è–ªæˆ–å…¼èŒï¼‰
        df = df[(df['avg_salary'] < 50000) & (df['avg_salary'] > 2000)].copy()
        filtered_count = original_count - len(df)
        if filtered_count > 0:
            logging.info(f"   âš ï¸ å·²è¿‡æ»¤ {filtered_count} ä¸ªå¼‚å¸¸è–ªèµ„æ ·æœ¬ï¼ˆç¡®ä¿æ•°æ®è´¨é‡ï¼‰")
        
        # --- 3. ç»éªŒå­¦å† ---
        exp_deg = df['raw_text'].apply(self._parse_exp_degree)
        df['exp_years'], df['degree_value'] = zip(*exp_deg)
        
        return df

    def feature_engineering(self, df):
        logging.info("ğŸ§  ç”Ÿæˆ NLP ç‰¹å¾...")
        skills = ['Python', 'SQL', 'Excel', 'Tableau', 'PowerBI', 'Spark', 'Hadoop', 'Machine Learning', 'Java']
        
        text_data = (df['title'] + ' ' + df['raw_text']).fillna('').str.lower()
        
        for skill in skills:
            df[f'has_{skill}'] = text_data.apply(lambda x: 1 if skill.lower() in x else 0)
            
        return df

    def run(self):
        df = self.load_data()
        df = self.clean_data(df)
        df = self.feature_engineering(df)
        
        # æ‰“å°ä¿®å¤åçš„å¯¹æ¯”ï¼Œè®©ä½ æ”¾å¿ƒ
        logging.info("ğŸ“Š åŸå¸‚ä¿®å¤æ•ˆæœæŠ½æŸ¥:")
        print(df[['city_clean', 'raw_text']].tail(5).to_string())
        
        df.to_sql(self.clean_table, self.engine, if_exists='replace', index=False)
        logging.info(f"âœ… å¤„ç†å®Œæˆï¼Œæ•°æ®å·²å­˜å…¥æ•°æ®åº“: {len(df)} æ¡")

if __name__ == "__main__":
    DataPipeline().run()